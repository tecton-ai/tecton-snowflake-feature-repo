{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Tecton on Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "Before getting started, lets do some setup to get your computer ready to interact with Tecton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Install the Tecton CLI on your local machine\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Tecton requires Python version 3.8 to run. We also recommend installing tecton into a Python virtual environment.\n",
    "</div>\n",
    "\n",
    "To install the Tecton CLI and other dependencies on your local machine, run the following command in this folder:\n",
    "\n",
    "✅ `$ pip install -r requirements.txt`\n",
    "\n",
    "If you run into any issues, follow [these instructions in the Tecton Docs](https://docs.tecton.ai/docs/setting-up-tecton/development-setup/installing-the-tecton-cli) to set up the Tecton CLI.\n",
    "\n",
    "Once you have finished installing the CLI, you can log in to your Tecton instance using (please replace `<your-cluster>` with your instance name):\n",
    "\n",
    "✅ `$ tecton login <your-instance>.tecton.ai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Clone the Tecton Sample Repository\n",
    "\n",
    "This tutorial will use [a sample repository full of pre-built features and data sources](https://github.com/tecton-ai-ext/tecton-snowflake-feature-repo).\n",
    "\n",
    "Before you get started, clone this repository to your local machine using:\n",
    "\n",
    "✅ `$ git clone https://github.com/tecton-ai-ext/tecton-snowflake-feature-repo.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Configure your environment with Snowflake Credentials\n",
    "\n",
    "You'll need to set three environment variables to connect to snowflake, we recommend storing them in a file called `.env`\n",
    "* SNOWFLAKE_USER: your username in the Snowflake account that you're using with Tecton\n",
    "* SNOWFLAKE_PASSWORD: your password in in the Snowflake account that you're using with Tecton\n",
    "* SNOWFLAKE_ACCOUNT: the Snowflake account you're using with Tecton (takes the form \\<SNOWFLAKE_ACCOUNT\\>.snowflakecomputing.com\n",
    "\n",
    "You can uncomment the cell below to create this file, or create it manually in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile .env\n",
    "# SNOWFLAKE_USER=\"<YOUR_SNOWFLAKE_USER>\"\n",
    "# SNOWFLAKE_PASSWORD=\"<YOUR_SNOWFLAKE_PASSWORD>\"\n",
    "# SNOWFLAKE_ACCOUNT=\"<SNOWFLAKE_ACCOUNT>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Import some packages and check that Tecton is installed\n",
    "\n",
    "✅ Run the cell below. It will infer the Snowflake credentials from the configuration you set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tecton and other libraries\n",
    "import logging\n",
    "import os\n",
    "import tecton\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv(find_dotenv())  # take environment variables from .env.\n",
    "\n",
    "logging.getLogger('snowflake.connector').setLevel(logging.WARNING)\n",
    "logging.getLogger('snowflake.snowpark').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"user\": os.environ['SNOWFLAKE_USER'],\n",
    "    \"password\": os.environ['SNOWFLAKE_PASSWORD'],\n",
    "    \"account\": os.environ['SNOWFLAKE_ACCOUNT'],\n",
    "    \"warehouse\": \"TRIAL_WAREHOUSE\",\n",
    "    # Database and schema are required to create various temporary objects by tecton\n",
    "    \"database\": \"TECTON\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "conn = snowflake.connector.connect(**connection_parameters)\n",
    "tecton.snowflake_context.set_connection(conn) # Tecton will use this Snowflake connection for all interactive queries\n",
    "\n",
    "\n",
    "# Quick helper function to query snowflake from a notebook\n",
    "# Make sure to replace with the appropriate connection details for your own account\n",
    "def query_snowflake(query):\n",
    "    df = conn.cursor().execute(query).fetch_pandas_all()\n",
    "    return df\n",
    "\n",
    "print(\"dotenv location: \" + find_dotenv())\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Interacting with Tecton\n",
    "Your Tecton account has been seeded with data and some example features that you can use to test out Tecton.\n",
    "\n",
    "First, you can check out some of the raw data that has been connected to Tecton -- historical transactions.  You'll notice we first select the [Tecton workspace](https://docs.tecton.ai/docs/introduction/tecton-concepts#workspace) that contains the objects we want to fetch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the data source in Snowflake\n",
    "ws = tecton.get_workspace('prod')\n",
    "ds = ws.get_data_source('transactions')\n",
    "ds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Preview the raw data directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data directly\n",
    "transactions_query = '''\n",
    "SELECT \n",
    "    *\n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS \n",
    "ORDER BY TIMESTAMP DESC\n",
    "LIMIT 50\n",
    "'''\n",
    "transactions = query_snowflake(transactions_query)\n",
    "transactions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Tecton Feature Views\n",
    "\n",
    "In Tecton, features are registered as [Feature Views](https://docs.tecton.ai/docs/defining-features/feature-views/).  These views contain all of the information needed to transform raw data (like transactions) into features.\n",
    "\n",
    "Let's run the \"Merchant Fraud Rate\" Feature View to view feature data from the last 30 days (sorted by the merchants with the highest fraud rate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = ws.get_feature_view('merchant_fraud_rate')\n",
    "\n",
    "today = \"2023-01-01 00:00:00\" # change to today's date/the latest date shown in the results for call 2.1\n",
    "\n",
    "start_time = datetime.strptime(today, '%Y-%m-%d %H:%M:%S')-timedelta(days=40)\n",
    "end_time = datetime.strptime(today, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "features = fv.run(start_time=start_time, end_time=end_time).to_pandas()\n",
    "\n",
    "features.sort_values(by=\"IS_FRAUD_MEAN_3D_1D\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generating Training Data\n",
    "Once you've built a number of features, you'll want to join them together to generate training data. \n",
    "\n",
    "### 3.1) Tecton Feature Services\n",
    "In Tecton, features that are needed for training or predictions are grouped together into a [Feature Service](https://docs.tecton.ai/docs/defining-features/feature-services). Typically you have one Feature Service per ML model. Let's check out a Feature Service that we've already built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = ws.get_feature_service('fraud_detection_feature_service')\n",
    "fs.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fraud_detection_feature_service` is comprised of 13 features that are meant to be used together to train a fraud detection model.\n",
    "\n",
    "### 3.2) Building a Spine\n",
    "\n",
    "Let's use the `fraud_detection_feature_service` to train a model that scores transactions as either \"Fraudulent\" or \"Non-Fraudulent\".  To start, lets look up some labeled transactions that we'll use for training.\n",
    "\n",
    "We can see in the summary above that the `fraud_detection_feature_service` requires `USER_ID` and `CATEGORY` join keys in order to fetch all the relevant features. Together with an event timestamp and label column, this represents our list of historical training events. In Tecton we call this a \"spine\".\n",
    "\n",
    "See the [documentation](https://docs.tecton.ai/docs/reading-feature-data/reading-feature-data-for-training/constructing-training-data) for more context on creating training data with Tecton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the label data directly\n",
    "transactions_query = '''\n",
    "SELECT \n",
    "    MERCHANT,\n",
    "    USER_ID,\n",
    "    CATEGORY,\n",
    "    TIMESTAMP,\n",
    "    IS_FRAUD\n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS \n",
    "ORDER BY TIMESTAMP DESC\n",
    "LIMIT 1000\n",
    "'''\n",
    "transactions = query_snowflake(transactions_query)\n",
    "transactions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Getting Training Data with `get_historical_features`\n",
    "\n",
    "To retrieve training data, we'll use Tecton's `get_historical_features` API, which allows us to join the 13 features contained in `fraud_detection_feature_service` onto our historical transactions.\n",
    "\n",
    "\n",
    "A Feature Service will expect a spine in the form of a Pandas Dataframe or a Snowflake query that generates the events as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = fs.get_historical_features(spine=transactions_query, timestamp_key=\"TIMESTAMP\").to_pandas()\n",
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Getting Real-Time Features for Inference\n",
    "\n",
    "### 4.1) Authenticating with an API key\n",
    "Follow [these instructions](https://docs.tecton.ai/docs/reading-feature-data/reading-feature-data-for-inference/reading-online-features-for-inference-using-the-python-sdk-for-testing) to get an API key for retrieving real-time features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Retrieve online features using the Python SDK\n",
    "\n",
    "We can hit Tecton's REST API directly from the Python SDK using `fs.get_online_features(keys)`. This method is convenient for testing purposes.\n",
    "\n",
    "✅ To query the REST API from the Python SDK, we need to set the API key in the first line of the cell below. Replace \"\\<key>\" with the token generated in the step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tecton.conf.set(\"TECTON_API_KEY\", \"...\")\n",
    "\n",
    "keys = {\n",
    "    'USER_ID': 'user_461615966685',\n",
    "    'CATEGORY': 'grocery_net'\n",
    "}\n",
    "features = fs.get_online_features(join_keys=keys).to_dict()\n",
    "pprint(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Retrieve features directly from the REST API via a cURL\n",
    "\n",
    "We can also directly query Tecton's REST API using the example cURL below.\n",
    "\n",
    "✅ Run this in your terminal, but make sure to replace `<your-cluster>` cluster name in the first line with your cluster name:\n",
    "\n",
    "```bash\n",
    "curl -X POST --silent https://<your-cluster>.tecton.ai/api/v1/feature-service/get-features\\\n",
    "     -H \"Authorization: Tecton-key $TECTON_API_KEY\" -d\\\n",
    "'{\n",
    "  \"params\": {\n",
    "    \"feature_service_name\": \"fraud_detection_feature_service\",\n",
    "    \"join_key_map\": {\n",
    "      \"USER_ID\": \"user_461615966685\",\n",
    "      \"CATEGORY\": \"grocery_net\"\n",
    "    },\n",
    "    \"workspace_name\": \"prod\"\n",
    "  }\n",
    "}' | jq\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Next\n",
    "\n",
    "Tecton is a powerful tool to build, manage, share, and consume features for ML.  Check out the next tutorial \"Creating Features on Snowflake\" to learn how to build your own features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5bad87e5f01eb332117191e01dc1d8a2d8b326d0fb92b63ba9a5b49c69d33bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
