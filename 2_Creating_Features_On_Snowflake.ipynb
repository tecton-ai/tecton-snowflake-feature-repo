{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building Features with Tecton and Snowflake\n",
    "\n",
    "In this tutorial we'll cover how you can use Tecton and Snowflake to build features for machine learning.  We'll cover:\n",
    "* How to register features with Tecton\n",
    "* How features are written in Tecton\n",
    "* How to use Tecton Aggregations to do easy window aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "✅ Run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import tecton\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from datetime import date, datetime, timedelta\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "logging.getLogger('snowflake.connector').setLevel(logging.WARNING)\n",
    "logging.getLogger('snowflake.snowpark').setLevel(logging.WARNING)\n",
    "\n",
    "connection_parameters = {\n",
    "    \"user\": os.environ['SNOWFLAKE_USER'],\n",
    "    \"password\": os.environ['SNOWFLAKE_PASSWORD'],\n",
    "    \"account\": os.environ['SNOWFLAKE_ACCOUNT'],\n",
    "    \"warehouse\": \"TRIAL_WAREHOUSE\",\n",
    "    # Database and schema are required to create various temporary objects by tecton\n",
    "    \"database\": \"TECTON\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "conn = snowflake.connector.connect(**connection_parameters)\n",
    "tecton.snowflake_context.set_connection(conn) # Tecton will use this Snowflake connection for all interactive queries\n",
    "\n",
    "# Quick helper function to query snowflake from a notebook\n",
    "# Make sure to replace with the appropriate connection details for your own account\n",
    "def query_snowflake(query):\n",
    "    df = conn.cursor().execute(query).fetch_pandas_all()\n",
    "    return df\n",
    "\n",
    "ws = tecton.get_workspace('prod')\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Before we start -- Tecton Workspaces\n",
    "\n",
    "[Workspaces](https://docs.tecton.ai/overviews/workspaces.html) are like a sandbox environment that can be used for experimenting with a Feature Repo without affecting the production environment. Changes made in one workspace will have no affect on other Workspaces.\n",
    "\n",
    "By default, new \"development\" workspaces do not have access to materialization and storage resources. Instead, transformations can be run ad-hoc in your Snowflake Warehouse. This means that the Tecton SDK builds a query that reads directly from your raw data tables, and executes it in your Snowflake Warehouse.\n",
    "\n",
    "This ad-hoc computation functionality can be used in any workspace and allows you to easily test features without needing to backfill and materialize data to the Feature Store.\n",
    "\n",
    "New workspaces with full materialization and storage resources can be created with the addition of the _--live_ flag during create time in the below CLI command. This can be useful for creating staging environments for testing features online before pushing changes to prod, or for creating isolation between different teams.\n",
    "\n",
    "**In this tutorial, we'll create a new workspace to ensure our changes don't effect other's workloads**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Create your own Tecton Workspace\n",
    "In this tutorial, we'll create a new [Workspace](https://docs.tecton.ai/docs/setting-up-tecton/administration-setup/creating-a-workspace-and-adding-users-to-the-workspace) to test our changes.\n",
    "\n",
    "Workspaces are created using the Tecton CLI. Let's make one now:\n",
    "\n",
    "Create a workspace by running `tecton workspace create YOUR_NAME`.\n",
    "\n",
    "```\n",
    "$ tecton workspace create YOUR_NAME\n",
    "Created workspace \"YOUR_NAME\".\n",
    "Switched to workspace \"YOUR_NAME\".\n",
    "\n",
    "You're now on a new, empty workspace. Workspaces isolate their state,\n",
    "so if you run \"tecton plan\" Tecton will not see any existing state\n",
    "for this configuration.\n",
    "```\n",
    "\n",
    "> 💡**Tip:** For a complete list of workspace commands, simply run `tecton workspace -h`\n",
    "\n",
    "Then, grab a reference to the new Workspace you created that we'll reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = tecton.get_workspace(\"YOUR_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Clone the Sample Feature Repo\n",
    "In Tecton, a [feature repository](https://docs.tecton.ai/docs/introduction/tecton-concepts#feature-repository) is a collection of declarative Python files that define feature pipelines. In this tutorial, we'll clone a pre-populated feature repository to use as a starting point.\n",
    "\n",
    "The [sample feature repository for this demo can be found here](https://github.com/tecton-ai-ext/tecton-snowflake-feature-repo) -- if you already checked out this git repository to get a copy of this tutorial, you should already have the important files downloaded.  If not, clone the sample repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Apply the Sample Feature Repo\n",
    "\n",
    "To register a local feature repository with Tecton, [you'll use the Tecton CLI.](https://docs.tecton.ai/examples/managing-feature-repos.html) Since you are working in a new Workspace, it does not currently have anything registered, so your first time adding features should be simple.\n",
    "\n",
    "Navigate to the feature repository's directory in the command line:\n",
    "```\n",
    "cd feature_repo\n",
    "```\n",
    "\n",
    "\n",
    "Then run the following command to register your feature definitions with Tecton:\n",
    "```\n",
    "tecton apply\n",
    "```\n",
    "\n",
    "\n",
    "Take note of the workspace you are applying to to make sure it is correct. Then go ahead and apply the plan with `y`.\n",
    "\n",
    "> 💡 **Tip:** You can always compare your local Feature Repo to the remote Feature Registry before applying it by running `tecton plan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Feature\n",
    "Let's start by building a simple feature -- **the amount of the last transaction a user made**. First, let's run a query against the raw data in Snowflake (feel free to run this yourself in a Snowflake worksheet as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data directly\n",
    "user_transaction_amount_query = '''\n",
    "SELECT \n",
    "    USER_ID,\n",
    "    AMT,\n",
    "    TIMESTAMP\n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS LIMIT 10 \n",
    "'''\n",
    "user_transaction_amount = query_snowflake(user_transaction_amount_query)\n",
    "user_transaction_amount.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tecton, a feature has **three key components**:\n",
    "1. A set of keys that specify who or what the feature is describing (associated with an [Entity](https://docs.tecton.ai/overviews/framework/entities.html)). In the above example, the key is `USER_ID`, meaning this feature is describing a property about a user.\n",
    "2. One or more feature values -- the stuff that's going to eventually get passed into a model.  In the above example, the feature is `AMT`, the amount of the transaction.\n",
    "3. A timestamp for the feature value. In the above example, the timestamp is `TIMESTAMP`, signifying that the feature is valid as of the moment of the transaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Feature to Tecton\n",
    "Moving from your Snowflake query to a Tecton feature is very simple, you'll simply wrap the SQL query in a Tecton python decorator.  Here's what it looks like in practice:\n",
    "\n",
    "```python\n",
    "@batch_feature_view(\n",
    "    sources=[transactions],\n",
    "    entities=[user],\n",
    "    mode='snowflake_sql',\n",
    "    online=True,\n",
    "    batch_schedule=timedelta(days=1),\n",
    "    ttl=timedelta(days=30),\n",
    "    feature_start_time=datetime(2021, 5, 20),\n",
    "    description='Last user transaction amount (batch calculated)'\n",
    ")\n",
    "def user_last_transaction_amount(transactions):\n",
    "    return f'''\n",
    "        SELECT\n",
    "            USER_ID,\n",
    "            AMT,\n",
    "            TIMESTAMP\n",
    "        FROM\n",
    "            {transactions}\n",
    "        '''\n",
    "```\n",
    "\n",
    "✅  To add this feature to Tecton, simply add it to a new file in your Tecton Feature Repository. **For your convenience, you can find this feature implemented (and commented out) [in this file](https://github.com/tecton-ai-ext/tecton-snowflake-feature-repo/blob/main/feature_repo/features/batch_feature_views/user_last_transaction_amount.py)**.\n",
    "\n",
    "✅  Once you save your new feature, run `tecton apply` to publish it to Tecton.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.list_feature_views()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = ws.get_feature_view('user_last_transaction_amount')\n",
    "\n",
    "start_time = datetime.utcnow()-timedelta(days=60)\n",
    "end_time = datetime.utcnow()\n",
    "\n",
    "fv.run(start_time=start_time, end_time=end_time).to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tecton time-windowed aggregations\n",
    "Sliding time-windowed aggregations are common ML features for event data, but defining them in a view can be error-prone and inefficient.\n",
    "\n",
    "Tecton provides built-in implementations of common time-windowed aggregations that simplify transformation logic and ensure correct feature value computation. Additionally, Tecton optimizes the compute and storage of these aggregations to maximize efficiency.\n",
    "\n",
    "For these reasons, we recommend using Tecton’s built-in aggregations whenever possible.\n",
    "\n",
    "Time-windowed aggregations can be specified in the [Batch Feature View](https://docs.tecton.ai/docs/defining-features/feature-views/batch-feature-view/#creating-features-that-use-time-windowed-aggregations) decorator using the `aggregations` and `aggregation_slide_period` parameters.\n",
    "\n",
    "Tecton expects the provided SQL query to select the raw events (with timestamps) to be aggregated.\n",
    "\n",
    "```python\n",
    "@batch_feature_view(\n",
    "    sources=[transactions],\n",
    "    entities=[user],\n",
    "    mode='snowflake_sql',\n",
    "    online=True,\n",
    "    feature_start_time=datetime(2021, 5, 20),\n",
    "    description='Max transaction amounts for the user in various time windows',\n",
    "    aggregation_interval=timedelta(days=1),\n",
    "    aggregations=[\n",
    "        Aggregation(column='AMT', function='max', time_window=timedelta(days=1)),\n",
    "        Aggregation(column='AMT', function='max', time_window=timedelta(days=30)),\n",
    "        Aggregation(column='AMT', function='max', time_window=timedelta(days=180)),\n",
    "    ],)\n",
    "def user_max_transactions(transactions):\n",
    "    return f'''\n",
    "        SELECT\n",
    "            USER_ID,\n",
    "            AMT,\n",
    "            TIMESTAMP\n",
    "        FROM\n",
    "            {transactions}\n",
    "        '''\n",
    "```\n",
    "\n",
    "✅  To add this feature to Tecton, simply add it to a new file in your Tecton Feature Repository. **For your convenience, you can find this feature implemented (and commented out) [in this file](https://github.com/tecton-ai-ext/tecton-snowflake-feature-repo/blob/main/feature_repo/features/batch_feature_views/user_max_transactions.py)**.\n",
    "\n",
    "✅  Once you save your new feature, run `tecton apply` to publish it to Tecton.\n",
    "\n",
    "Now we can test this feature below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = ws.get_feature_view('user_max_transactions')\n",
    "\n",
    "start_time = datetime.combine(date.today()-timedelta(days=180), datetime.min.time())\n",
    "end_time = datetime.combine(date.today(), datetime.min.time())\n",
    "\n",
    "fv.run(start_time=start_time, end_time=end_time).to_pandas().fillna(0).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
